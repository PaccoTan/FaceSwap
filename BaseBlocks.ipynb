{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6989ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU,BatchNormalization, UpSampling2D, ReLU\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c9ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottle_block(x,units=64,kernel=3):\n",
    "    out = conv_block(x,units,kernel,1)\n",
    "    out = Conv2D(units,kernel,1,padding=\"same\")(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = out + x\n",
    "    out = ReLU()(out)\n",
    "    return out\n",
    "\n",
    "def conv_block(x,units,kernel=3,stride=1,activation=ReLU):\n",
    "    out = Conv2D(units,kernel,stride,padding=\"same\")(x)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = activation()(out)\n",
    "    return out\n",
    "\n",
    "def up_block(x,units=64,kernel=3):\n",
    "    out = UpSampling2D(2,interpolation=\"bilinear\")(x)\n",
    "    out = conv_block(out,units,kernel,1)\n",
    "    return out\n",
    "\n",
    "def down_block(x,units=64,kernel=3):\n",
    "    out = conv_block(x,units,kernel,2)\n",
    "    out = conv_block(out,units,kernel,1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(input_shape,units=64,layers=1,num_blocks=6,out_channels=6):\n",
    "    x = keras.layers.Input(input_shape)\n",
    "    g2 = conv_block(x,units,7,1)\n",
    "    temp = units\n",
    "    skip = []\n",
    "    for i in range(0,layers):\n",
    "        g2 = down_block(g2,temp*2,3)\n",
    "        skip.append(g2)\n",
    "        temp *=2\n",
    "    \n",
    "    #code for local enhancer network\n",
    "    #not sure if needed to access local network output for training\n",
    "    local = None\n",
    "    for i in range(0,layers):\n",
    "        g2 = skip[-1-i]\n",
    "        local = g2\n",
    "        for j in range(0,num_blocks):\n",
    "            local = bottle_block(local,temp)\n",
    "        local = g2 + local\n",
    "        temp = temp//2\n",
    "        local = up_block(local,temp)\n",
    "    \n",
    "    g2 = local\n",
    "    for i in range(0,num_blocks):\n",
    "        g2 = bottle_block(g2,units)\n",
    "    g2 = conv_block(g2,out_channels,7)\n",
    "    g2 = tf.keras.activations.tanh(g2)\n",
    "    return keras.Model(x,g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8773d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape,n_units,levels,classes):\n",
    "    inputs = keras.layers.Input(shape=(input_shape))\n",
    "    output = inputs\n",
    "    units = n_units\n",
    "    #create array to store skip tensors\n",
    "    level = []\n",
    "    #Create contracting path\n",
    "    for i in range(0,levels):\n",
    "        output = keras.layers.Conv2D(units,3,strides=1,padding='same',activation='relu')(output)\n",
    "        output = keras.layers.Conv2D(units,3,strides=1,padding='same',activation='relu')(output)\n",
    "        #output = keras.layers.Dropout(0.1)(output)\n",
    "        level.append(output)\n",
    "        output = keras.layers.MaxPooling2D(pool_size=(2,2),strides=(2,2),padding=\"valid\")(output)\n",
    "        units = units * 2\n",
    "        \n",
    "    #Create expansion path    \n",
    "    for i in range(0,levels):\n",
    "        output = keras.layers.Conv2D(units,3,strides=1,padding='same',activation='relu')(output)\n",
    "        output = keras.layers.Conv2D(units,3,strides=1,padding='same',activation='relu')(output)\n",
    "        output = keras.layers.UpSampling2D(size =(2,2),interpolation=\"bilinear\")(output)\n",
    "        units = units//2\n",
    "        output = keras.layers.Conv2D(units,2,padding='same')(output)\n",
    "        output = tf.concat([level[-1-i],output],axis=3)\n",
    "    \n",
    "    #outputting segmentation map\n",
    "    output = keras.layers.Conv2D(units,3,strides=1,padding='same',activation='relu')(output)\n",
    "    output = keras.layers.Conv2D(units,3,strides=1,padding='same',activation='relu')(output)\n",
    "    output = keras.layers.Conv2D(classes,1,padding='same',activation='softmax')(output)\n",
    "    model = keras.Model(inputs,output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67364a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x,n_units=64,layers=3):\n",
    "    temp = n_units\n",
    "    out = Conv2D(temp,4,2,padding=\"same\")(x)\n",
    "    out = LeakyReLU()(out)\n",
    "    for i in range(1,layers):\n",
    "        temp = n_units*2\n",
    "        out = conv_block(out,temp,4,2,activation=LeakyReLU)\n",
    "    temp = n_units*2\n",
    "    out = conv_block(out,temp,4,1,activation=LeakyReLU)\n",
    "    out = Conv2D(1,4,1,padding=\"same\")(out)\n",
    "    out = keras.layers.Flatten()(out)\n",
    "    out = keras.activations.sigmoid(out)\n",
    "    return keras.Model(x,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiscale_discriminator(input_shape):\n",
    "    inputs = keras.layers.Input(input_shape)\n",
    "    out = None\n",
    "    return keras.Model(inputs,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa744bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = keras.applications.vgg19.VGG19(\n",
    "    include_top=True,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "pixel_weight = 0.1\n",
    "perceptual_weight = 1\n",
    "adversarial_weight = 0.001\n",
    "segmentation_weight = 0.1\n",
    "reconstruction_weight = 1\n",
    "stepwise_weight = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63491d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptual_loss(y_true, y_pred):\n",
    "    x = tf.image.resize(y_true,(224,224))\n",
    "    y = tf.image.resize(y_pred,(224,224))\n",
    "    x_vgg = vgg.predict(x)\n",
    "    y_vgg = vgg.predict(y)\n",
    "    loss = 0\n",
    "    loss +=  keras.losses.MeanAbsoluteError(x_vgg,y_vgg)\n",
    "    return loss\n",
    "def pixel_loss(x, y):\n",
    "    return keras.losses.MeanAbsoluteError(x,y)\n",
    "    \n",
    "def reconstruction_loss(x, y):\n",
    "    loss = 1*perceptual_loss(x,y) + 0.1*pixel_loss(x,y)\n",
    "    return loss\n",
    "def adversarial_loss(y_true, y_pred):\n",
    "    pass\n",
    "def poisson_blending_loss(y_true, y_pred):\n",
    "    return reconstruction_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f28e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset/CelebA-HQ-img/',\n",
    "    labels=None,\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")\n",
    "masks = tf.keras.utils.image_dataset_from_directory(\n",
    "    'dataset/CelebAMask-HQ-mask-anno/',\n",
    "    labels=\"inferred\",\n",
    "    label_mode='int',\n",
    "    class_names=['hair', 'skin'],\n",
    "    color_mode='grayscale',\n",
    "    batch_size=2,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation='nearest',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94861221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images in masks.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "image = tf.keras.utils.load_img(\n",
    "    \"C:/Users/jconn/Downloads/CelebAMask-HQ/CelebAMask-HQ/CelebA-HQ-img/0.jpg\",\n",
    "    grayscale=False,\n",
    "    color_mode='rgb',\n",
    "    target_size=None,\n",
    "    interpolation='nearest'\n",
    ")\n",
    "image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "image = tf.expand_dims(image, 0)\n",
    "\n",
    "image = tf.image.resize(image,(224,224))\n",
    "print(image.shape)\n",
    "out = vgg.predict(image)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aeb36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros((30000,256,256,2))\n",
    "for i in range(0,30000):\n",
    "    s = f'{i:05}'\n",
    "    try:\n",
    "        mask1=tf.keras.utils.load_img('./dataset/CelebAMask-HQ-mask-anno/hair/'+ s +\"_hair.png\", color_mode= \"grayscale\", target_size=(256,256), interpolation=\"nearest\")\n",
    "        mask1= tf.keras.preprocessing.image.img_to_array(mask1)\n",
    "\n",
    "    except:\n",
    "        mask1=tf.zeros((256,256,1))\n",
    "    mask2=tf.keras.utils.load_img('./dataset/CelebAMask-HQ-mask-anno/skin/'+ s +\"_skin.png\", color_mode= \"grayscale\", target_size=(256,256), interpolation=\"nearest\")\n",
    "    mask2= tf.keras.preprocessing.image.img_to_array(mask2)\n",
    "    mask[i] = tf.concat([mask1,mask2], -1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
